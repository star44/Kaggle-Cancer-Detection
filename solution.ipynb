{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'CAMELYON dataset.pdf',\n",
       " 'features.csv',\n",
       " 'histopathologic-cancer-detection',\n",
       " 'histopathologic-cancer-detection.zip',\n",
       " 'solution.ipynb']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up dataset\n",
    "\n",
    "A key finding in this project has been the size of the dataset that I have to navigate every time I want to create a batch. Since most of the processing is done using a backend written in C, it appears to be quick. However, the time taken to iterate over a list of imaged and read them into arrays may be what is making this network take so long!\n",
    "\n",
    "Therefore, I will be using the Keras `ImageDataGenerator` class! \n",
    "\n",
    "It needs the dataset to be split up by classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shutil import copyfile\n",
    "\n",
    "df = pd.read_csv('histopathologic-cancer-detection/train_labels.csv')\n",
    "cancer = df[df['label'] == 1]\n",
    "noncancer = df[df['label'] == 0]\n",
    "\n",
    "for filename in cancer['id']:\n",
    "    copyfile(\n",
    "        'histopathologic-cancer-detection/train/{0}'.format(filename + '.tif'),\n",
    "        'histopathologic-cancer-detection/train/cancer/{0}'.format(filename + '.tif')\n",
    "    )\n",
    "\n",
    "for filename in noncancer['id']:\n",
    "    copyfile(\n",
    "        'histopathologic-cancer-detection/train/{0}'.format(filename + '.tif'),\n",
    "        'histopathologic-cancer-detection/train/noncancer/{0}'.format(filename + '.tif')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a batch generator\n",
    "\n",
    "As per the keras documentation, the `flow_from_directory` function returns a tuple of (x, y) arrays. This is consistent with the format that can be used in the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220025 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "image_generator = keras.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "batch_generator = image_generator.flow_from_directory(\n",
    "    'histopathologic-cancer-detection/split_dataset/',\n",
    "    target_size=(96, 96),\n",
    "    class_mode='binary',\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a model\n",
    "\n",
    "I will attempt to define a model from scratch and train it on my GPU. It seems to perform quite well against the GPU benchmarks written in the keras examples so I have confidence. This message would not exist for long if I was not successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\n9183167\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\n9183167\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\n9183167\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/7\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.3985 - acc: 0.8293\n",
      "Epoch 2/7\n",
      "1000/1000 [==============================] - 162s 162ms/step - loss: 0.2773 - acc: 0.8862\n",
      "Epoch 3/7\n",
      "1000/1000 [==============================] - 163s 163ms/step - loss: 0.2348 - acc: 0.9080\n",
      "Epoch 4/7\n",
      "1000/1000 [==============================] - 156s 156ms/step - loss: 0.2092 - acc: 0.9188\n",
      "Epoch 5/7\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.1948 - acc: 0.9264\n",
      "Epoch 6/7\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.1803 - acc: 0.9319\n",
      "Epoch 7/7\n",
      "1000/1000 [==============================] - 149s 149ms/step - loss: 0.1676 - acc: 0.9372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a97ed4d0f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.backend import var, sum, min, max\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "model = Sequential()\n",
    "# Convolution layer 1\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        64,\n",
    "        kernel_size=(5, 5),\n",
    "        input_shape=(96, 96, 3),\n",
    "        padding='same',\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Convolution layer 2\n",
    "model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 48\n",
    "\n",
    "# Convolution layer 3\n",
    "model.add(Conv2D(64, (5, 5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 24\n",
    "\n",
    "# Convolution layer 4\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 12\n",
    "\n",
    "# Convolution layer 5\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # 6\n",
    "\n",
    "\n",
    "\n",
    "# FC\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.binary_crossentropy,\n",
    "    optimizer=keras.optimizers.Adadelta(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit_generator(\n",
    "    batch_generator,\n",
    "    steps_per_epoch=1000, \n",
    "    epochs=7\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\n9183167\\Documents\\ML\\Kaggle\\Cancer-Detection\\00006537328c33e284c973d7b39d340809f7271b.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-815461d25132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m test_image = imageio.imread(\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'histopathologic-cancer-detection/test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m )\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\kaggle-competitions\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\n9183167\\Documents\\ML\\Kaggle\\Cancer-Detection\\00006537328c33e284c973d7b39d340809f7271b.tif'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "test_image = os.listdir('histopathologic-cancer-detection/test')[0]\n",
    "imageio.imread(\n",
    "    \n",
    ")\n",
    "\n",
    "model.predict(\n",
    "    imageio.imread(\n",
    "        'histopathologic-cancer-detection/test/{0}'.format(test_image)\n",
    "    )\n",
    ")[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57458/57458 [06:58<00:00, 137.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "image_files = np.asarray(\n",
    "    os.listdir('histopathologic-cancer-detection/test/')\n",
    ")\n",
    "\n",
    "dataset = []\n",
    "for image_file in tqdm(image_files):\n",
    "    hash_id = image_file.split('.')[0]\n",
    "    prediction = model.predict(\n",
    "        imageio.imread('histopathologic-cancer-detection/test/{0}'.format(image_file)).reshape(1, 96, 96, 3)\n",
    "    )\n",
    "    dataset.append([hash_id, prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset, columns=['id', 'label'])\n",
    "df.to_csv('solution.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
